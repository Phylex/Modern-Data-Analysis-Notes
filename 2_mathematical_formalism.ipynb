{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modern Methods of Data Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical formulation of Probability\n",
    "As many things in mathematics Statistics is based on set theort. Subsequently all quantities are described via Sets.\n",
    "Let's consider some hypothetical experiment. The different states of the Experiment are illustrated below.\n",
    "\n",
    "<img src=\"graphics/Probabilities.svg\">\n",
    "\n",
    "Let's also assume, that all possible outcomes of the experiment are known (the experiment may be a dice throw where there are only 6 possible outcomes if we assume it is a 6 sided dice ( and, well, if we disregard the exact position that the dice ends up in after the throw, but for most games it is irrelevant where the dice ends up (maybe under the table?) as long as the number shown can be read).\n",
    "Then $S$ is the state space of all possible outcomes of the experiment. As $A$ and $B$ lie within $S$ they are subsets of $S$.\n",
    "\n",
    "As all possible outcomes are contained in $S$ from which follows $P(S) = 1$, so in the frequentist interpretation is that the every measured quantity lies in $S$, or in bayesian interpretation the statement, \"all measurements lie within $S$\" is true.\n",
    "\n",
    "For most part, when looking at experiments, the frequentist interpretation is a bit more helpful which is why focus is placed on this interpretation for now.\n",
    "As for $A$ and $B$, as both are subsets of $S$ it can be deduced that $P(A) < P(S)$ and $P(B) < P(S)$, as both $A \\subset S$ and $B \\subset S$ (note that they are proper subsets).\n",
    "\n",
    "If it is of interest that the experiments produces a result that is either in $A$ or in $B$ and they satisfy $A \\cup B = \\emptyset$ (as shown in the illustration above) then it can be shown that $P(A\\cup B) = P(A) + P(B)$\n",
    "\n",
    "These three traits are know as the **Kolmogorov Axioms** and are written more concicely below\n",
    "\n",
    "\n",
    "$$1 \\geq P(A) \\geq 0; \\forall A \\subseteq S \\land A \\neq \\emptyset$$\n",
    "\n",
    "$$P(S) = 1$$\n",
    "\n",
    "$$P(A \\cup B) = P(A) + P(B); A \\cap B = \\emptyset$$\n",
    "\n",
    "It can also be of interest to know the probability of a measurement not being in $A$. Even if a mesurement is not in $A$ it by definition has to be in $S$. An event therefore can only be in $S \\setminus A = \\bar{A}$. The probability $P(\\bar{A}) = P(S) - P(A) = 1 - P(A)$, which is how the **NOT** definition from the previous Notebook can be derived using set theory. It trivially follows, that $P(A \\cup \\bar{A}) = P(S) = 1$ and that $P(A \\cap \\bar{A}) = 0$.\n",
    "\n",
    "As it is impossible to conduct the experiment and not produce a result it follows that $P(\\emptyset) = 0$\n",
    "\n",
    "### Intersecting sets and conditional probability\n",
    "Now that we have measured the States corresponding to $A$ and $B$ lets assume there are two further states $C$ and $D$ that are of interest now. The following illustration shows how experimental outcomes for $C$ and $D$ are located within $S$\n",
    "\n",
    "<img src=\"graphics/intersecting_probabilities.svg\">\n",
    "\n",
    "As you can see, The measurements for $C$ and $D$ overlap. This means that the third Kologorov Axiom no longer holds for $C$ and $D$ as $C\\cap D \\neq \\emptyset$\n",
    "If we look at $P(C \\cup D) = P(C) + P(D)$ it is possible to see, that we are counting the Area $C\\cap D$ twice. Correcting for that we get:\n",
    "\n",
    "$$ P(C\\cup D) = P(C) + P(D) - P(C\\cap D); C\\cap D \\neq \\emptyset$$\n",
    "\n",
    "#### Conditional Probability\n",
    "Now that we have intersecting subsets of results we can ask another interesting question. Let's assume we can tune our experimental setup to only produce results from $C$. What's the new probability of obtaining a result in $D$? This question is akin to askin: Given that we know $C$ will occurr, what is the probability to get a result in $D$? This is called conditional probability. It is written as $P(C\\mid D)$ or (I think more clearly) as $P_C(D)$ which is the probability of obtaining a result in $D$ given that $C$ occurs.\n",
    "\n",
    "The thing is, that now we have \"redefined\" what $S$ is. By tweaking the experiment we have made $C$ the new $S$. So to account for that we have to reweigh the probabilitie of $P(C \\cap D)$ to fit that $P(C) = 1$. It follows that:\n",
    "\n",
    "$$P(C\\mid D) = P_C(D) = \\frac{P(C \\cap D)}{P(C)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
